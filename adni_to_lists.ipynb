{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to generate data lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_augm_params(max_augm_params):\n",
    "    import numpy.random as rnd\n",
    "    max_shift = max_augm_params['shift']\n",
    "    max_blur = max_augm_params['blur']\n",
    "    while True:\n",
    "        shift_x = rnd.randint(-max_shift, max_shift)\n",
    "        shift_y = rnd.randint(-max_shift, max_shift)\n",
    "        shift_z = rnd.randint(-max_shift, max_shift)\n",
    "        blur_sigma = float(rnd.randint(1000)) / 1000 * max_blur\n",
    "        if shift_x + shift_y + shift_z + blur_sigma > 0:\n",
    "            return (shift_x, shift_y, shift_z, blur_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_augm_lists(dirs_with_labels, new_size, max_augm_params, default_augm_params=None):\n",
    "    import numpy.random as rnd\n",
    "    import math\n",
    "    if new_size == None or len(dirs_with_labels) == new_size:\n",
    "        return [dwl + [default_augm_params] for dwl in dirs_with_labels]\n",
    "    augm_coeff = int(math.floor(new_size / len(dirs_with_labels)))\n",
    "    res = []\n",
    "    i = 0\n",
    "    for dwl in dirs_with_labels:\n",
    "        res.append(dwl + [(0, 0, 0, 0.0)])\n",
    "        i += 1\n",
    "        for _ in range(augm_coeff-1):\n",
    "            res.append(dwl + [generate_augm_params(max_augm_params)])\n",
    "            i += 1\n",
    "    while i < new_size:\n",
    "        ridx = rnd.randint(len(dirs_with_labels))\n",
    "        dwl = dirs_with_labels[ridx]\n",
    "        res.append(dwl +[generate_augm_params(max_augm_params)])\n",
    "        i += 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_lists_from_adni2(adni_root, max_augm_params, augm_factor, valid_prc = 0.25, test_prc = 0.25, shuffle_data=True, debug=True):\n",
    "    \n",
    "    import os\n",
    "    import numpy as np\n",
    "    import numpy.random as rnd\n",
    "\n",
    "    stage_dirs = {\n",
    "        'AD': '/AD/',\n",
    "        'MCI': '/MCI/',\n",
    "        'NC': '/NC/'\n",
    "    }\n",
    "\n",
    "    stage_dirs_root = {k: adni_root + v for k, v in stage_dirs.items()}\n",
    "    \n",
    "    default_augm = (0, 0, 0, 0.0)\n",
    "    \n",
    "    patients_MRI_train = []\n",
    "    patients_MD_train = []\n",
    "    patients_MRI_test = []\n",
    "    patients_MD_test = []\n",
    "    \n",
    "    \n",
    "    class_size = {k: len(os.listdir(stage_dirs_root[k])) for k in stage_dirs_root}\n",
    "    print('source patients:', class_size)\n",
    "\n",
    "    ts = int(min(class_size.values()) * test_prc)\n",
    "    test_size = {k: ts for k in stage_dirs_root}\n",
    "    valid_size = {k: int(class_size[k] * valid_prc) for k in stage_dirs_root}\n",
    "    train_size = {k: class_size[k] - test_size[k] - valid_size[k] for k in stage_dirs_root}\n",
    "    \n",
    "    print('source patients used for train:', train_size)\n",
    "    print('source patients used for validation:', valid_size)\n",
    "    print('source patients used for test', test_size)\n",
    "\n",
    "    train_size_balanced = int(max(train_size.values()) * augm_factor)\n",
    "    valid_size_balanced = int(max(valid_size.values()) * augm_factor)\n",
    "    print('train data will be augmented to %d samples by each class' % train_size_balanced)\n",
    "    print('validation data will be augmented to %d samples by each class' % valid_size_balanced)\n",
    "    print('test data will be augmented to %d samples by each class' % ts)\n",
    "    \n",
    "    train_lists_out = []\n",
    "    valid_lists_out = []\n",
    "    test_lists_out = []\n",
    "    \n",
    "    for k in stage_dirs_root:\n",
    "        stage_dir = stage_dirs[k]\n",
    "        patient_dirs = os.listdir(stage_dirs_root[k])\n",
    "        rnd.shuffle(patient_dirs)\n",
    "\n",
    "        test_dirs = patient_dirs[:test_size[k]]\n",
    "        valid_dirs = patient_dirs[test_size[k]:test_size[k]+valid_size[k]]\n",
    "        train_dirs = patient_dirs[test_size[k]+valid_size[k]:]\n",
    "                                 \n",
    "        train_lists = [[k, stage_dir + d + '/SMRI/', stage_dir + d + '/MD/'] for d in train_dirs]\n",
    "        valid_lists = [[k, stage_dir + d + '/SMRI/', stage_dir + d + '/MD/'] for d in valid_dirs]\n",
    "        test_lists = [[k, stage_dir + d + '/SMRI/', stage_dir + d + '/MD/'] for d in test_dirs]\n",
    "        \n",
    "        train_lists_out += generate_augm_lists(train_lists, train_size_balanced, max_augm_params)\n",
    "        valid_lists_out += generate_augm_lists(valid_lists, valid_size_balanced, max_augm_params)\n",
    "        test_lists_out += generate_augm_lists(test_lists, None, None, default_augm_params=default_augm)\n",
    "    \n",
    "    if shuffle_data:\n",
    "        rnd.shuffle(train_lists_out)\n",
    "        rnd.shuffle(valid_lists_out)\n",
    "        rnd.shuffle(test_lists_out)\n",
    "    \n",
    "    if debug:\n",
    "        print('### train lists (%d instances):' % len(train_lists_out))\n",
    "        for i in train_lists_out: print(i)\n",
    "        print('### valid lists (%d instances):' % len(valid_lists_out))\n",
    "        for i in valid_lists_out: print(i)\n",
    "        print('### test lists (%d instances):' % len(test_lists_out))\n",
    "        for i in test_lists_out: print(i)\n",
    "        \n",
    "        \n",
    "    return (train_lists_out, valid_lists_out, test_lists_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An example of how to do data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "lists_params = {\n",
    "    'adni_root': '/home/xubiker/ADNI_Multimodal/dataset/',\n",
    "    'max_augm': {'shift': 2, 'blur': 1.2},\n",
    "    'test_prc': 0.25,\n",
    "    'valid_prc': 0.25,\n",
    "    'augm_factor': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_params(params, file_path):\n",
    "    import pickle\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate lists..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_lists(lists_file_path, params, debug=True):\n",
    "    import ex_utils\n",
    "    train_list, valid_list, test_list = generate_lists_from_adni2(\n",
    "        params['adni_root'],\n",
    "        params['max_augm'], test_prc=params['test_prc'], valid_prc=params['valid_prc'],\n",
    "        augm_factor=params['augm_factor'],\n",
    "        shuffle_data=True, debug=debug\n",
    "    )\n",
    "    ex_utils.save_pickle((train_list, valid_list, test_list), lists_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ex_utils\n",
    "ex_utils.save_pickle(lists_params, 'params.pkl')\n",
    "generate_lists('lists.pkl', lists_params, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
