{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Some settings and configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ex_config\n",
    "ex_config.load_caffe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to save data to LMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initiate_lmdb(lmdb_name, drop_existing = False):\n",
    "    import lmdb\n",
    "    import caffe\n",
    "    import numpy as np\n",
    "    \n",
    "    if drop_existing:\n",
    "        import os\n",
    "        import shutil\n",
    "        if os.path.exists(lmdb_name):\n",
    "            shutil.rmtree(lmdb_name) \n",
    "    \n",
    "    env = lmdb.open(lmdb_name, map_size=int(1e12))\n",
    "    print('database debug info:', env.stat())\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_transaction(txn, data, label, key):\n",
    "    import caffe\n",
    "    datum = caffe.proto.caffe_pb2.Datum()\n",
    "    (datum.channels, datum.height, datum.width) = data.shape\n",
    "    datum.data = data.tobytes()\n",
    "    datum.label = label\n",
    "    key = '{:08}'.format(key)\n",
    "    txn.put(key.encode('ascii'), datum.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def array_to_proto(data, proto_name):\n",
    "    import caffe\n",
    "    blob = caffe.io.array_to_blobproto(data)\n",
    "    binaryproto_file = open(proto_name, 'wb+')\n",
    "    binaryproto_file.write(blob.SerializeToString())\n",
    "    binaryproto_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to validate LMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def debug_lmdb_print_info(lmdb_name):\n",
    "    import caffe\n",
    "    print('debug printing for \\'', lmdb_name, '\\' lmdb data')\n",
    "    env = initiate_lmdb(lmdb_name, drop_existing = False)\n",
    "    print(env.stat())\n",
    "    with env.begin() as txn:\n",
    "        cursor = txn.cursor()\n",
    "        datum = caffe.proto.caffe_pb2.Datum()\n",
    "        i = 0\n",
    "        for key, value in cursor:\n",
    "            i += 1\n",
    "            datum.ParseFromString(value)\n",
    "            print('inst %d of size (%d, %d, %d) labeled %d' % (i, datum.channels, datum.height, datum.width, datum.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def debug_lmdb_plot_slices(lmdb_name, data_type, print_slices=False):\n",
    "    import ex_utils\n",
    "    import numpy as np\n",
    "    #np.set_printoptions(threshold=np.inf)\n",
    "    import caffe\n",
    "    import matplotlib.pyplot as plt\n",
    "    print('debug plotting slices for \\'%s\\' lmdb data' % lmdb_name)\n",
    "    env = initiate_lmdb(lmdb_name, drop_existing = False)\n",
    "    with env.begin() as txn:\n",
    "        cursor = txn.cursor()\n",
    "        datum = caffe.proto.caffe_pb2.Datum()\n",
    "        cursor.next();\n",
    "        value = cursor.value();\n",
    "        datum.ParseFromString(value)\n",
    "        flat_x = np.fromstring(datum.data, dtype=data_type)\n",
    "        x = flat_x.reshape(datum.channels, datum.height, datum.width)\n",
    "        ex_utils.debug_plot_median_slices(x, print_slices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to postprocess data lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_multiimage_set(xset, suffix):\n",
    "    from xsets import XSet, XSetItem\n",
    "    sets = [XSet(name=xset.name+'_'+s) for s in suffix]\n",
    "    for j in range(len(suffix)):\n",
    "        sets[j].items = [XSetItem(i.label, [i.image_dirs[j]], i.augm_params) for i in xset.items]\n",
    "    return sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_sets_to_binary(xset):\n",
    "    import ex_config as cfg\n",
    "    from xsets import XSet\n",
    "    groups = { f: XSet(name=xset.name+'_'+f) for f in cfg.get_bin_label_families() }\n",
    "    for item in xset.items:\n",
    "        for f in cfg.get_bin_label_families(item.label):\n",
    "            groups[f].add(item)\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to generate mean file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_lmdb_mean(lmdb_path, data_type, reshape_4D = True, plot_mean = True):\n",
    "    import ex_utils\n",
    "    import caffe\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    env = initiate_lmdb(lmdb_path, drop_existing = False)\n",
    "    mean = np.empty\n",
    "    i = 0\n",
    "    with env.begin() as txn:\n",
    "        datum = caffe.proto.caffe_pb2.Datum()\n",
    "        cursor = txn.cursor()\n",
    "        cursor.next();\n",
    "        datum.ParseFromString(cursor.value())\n",
    "        mean = np.zeros([datum.channels, datum.height, datum.width])\n",
    "        cursor = txn.cursor()\n",
    "        for key, value in cursor:\n",
    "            i += 1\n",
    "            datum.ParseFromString(value)\n",
    "            flat = np.fromstring(datum.data, dtype=data_type)\n",
    "            x = flat.reshape(datum.channels, datum.height, datum.width)\n",
    "            mean = np.add(mean, x)\n",
    "    mean = np.divide(mean, i)\n",
    "    if plot_mean:\n",
    "        ex_utils.debug_plot_median_slices(mean)\n",
    "    if reshape_4D:\n",
    "        mean = mean.reshape((1,) + mean.shape)\n",
    "        print('mean image reshaped to', mean.shape)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to create lmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xset_to_lmdb(xset, adni_root, data_type, label_family, max_augm_params, crop_params=None, crop_roi_params=None):\n",
    "    import ex_config\n",
    "    import preprocessing as pp\n",
    "    env = initiate_lmdb(xset.name, drop_existing = True)\n",
    "    key = 0\n",
    "    with env.begin(write=True) as txn:\n",
    "        for i in xset.items:\n",
    "            augm = pp.full_preprocess(i, adni_root, data_type, max_augm_params, crop_params, crop_roi_params)\n",
    "            print('%d. writing image of shape %s to lmdb (%s)' % (key, str(augm.shape), i.image_dirs[0]))\n",
    "            write_to_transaction(txn, augm, ex_config.get_label_code(label_family, i.label), key)\n",
    "            key += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An example of how to do data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import augmentation as augm\n",
    "\n",
    "lmdb_params = {\n",
    "    'adni_root': '/home/xubiker/ADNI_Multimodal/dataset/',\n",
    "    'max_augm': augm.AugmParams(shift=(2, 2, 2), sigma=1.2),\n",
    "    'dtype': np.float,\n",
    "\n",
    "    'crop_params': None,#{'shift': (0, 0, -0.05), 'prc': (0.05, 0.05, 0.05)},\n",
    "    'crop_roi_params': (65-2, 92+1-2, 58-2, 85+1-2, 31-2, 58+1-2) # max_shift substracted\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process lists. Write them to lmdb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lmdb_from_sets(sets_path, params, create_binary_lmdbs=False, normalize_labels=False):\n",
    "    \n",
    "    import pickle\n",
    "    with open(sets_path, 'rb') as f:\n",
    "        train, valid, test = pickle.load(f)\n",
    "    \n",
    "    train_mri, train_dti = split_multiimage_set(train, suffix=('sMRI', 'MD'))\n",
    "    valid_mri, valid_dti = split_multiimage_set(valid, suffix=('sMRI', 'MD'))\n",
    "    test_mri, test_dti = split_multiimage_set(test, suffix=('sMRI', 'MD'))\n",
    "\n",
    "    for xset in (test_mri,):\n",
    "#     for xset in (train_mri, train_dti, valid_mri, valid_dti, test_mri, test_dti):\n",
    "        queue = [(xset, 'ternary')]\n",
    "        if create_binary_lmdbs:\n",
    "            queue = []\n",
    "            bin_groups = split_sets_to_binary(xset)\n",
    "            for k in bin_groups:\n",
    "                label_family = k if normalize_labels else 'ternary'\n",
    "                queue.append((bin_groups[k], label_family))\n",
    "        for (xs, f) in queue:\n",
    "            xset_to_lmdb(\n",
    "                xs, adni_root=params['adni_root'], data_type=params['dtype'], label_family=f,\n",
    "                max_augm_params=params['max_augm'], \n",
    "                crop_params=params['crop_params'], crop_roi_params=params['crop_roi_params']\n",
    "             )\n",
    "            debug_lmdb_print_info(xs.name)\n",
    "            debug_lmdb_plot_slices(xs.name, data_type=params['dtype'])\n",
    "            mean = calc_lmdb_mean(xs.name, data_type=params['dtype'], reshape_4D=True, plot_mean=True)\n",
    "            array_to_proto(data=mean, proto_name=xs.name+'_mean.binaryproto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_lmdb_from_sets('sets.pkl', lmdb_params, create_binary_lmdbs=True, normalize_labels=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
